import json

# Define an Agent class that runs a structured Thought -> Action -> Observation -> Final loop
class Agent:
  def __init__(self, client, tools_list):
    # Save the LLM client (OpenAI client)
    self.client = client
    
    # Define the system prompt with rules for loop stages and JSON format
    self.system = """
      You are a project manager with a knack for design sense and love for beautiful landing pages. 
      Given a user's task, you must work in a process following the loop of Thought, Action, Observation, 
      to produce what the user wants. At the end of the loop, you output a final Answer.

      You must understand the task the user is asking of you, and generate code that perfectly fits 
      their request in accordance with your abilities.

      Below are your available actions:

      ## 1. generate_css
      ### Input parameters:
      1. html_code: string [The HTML code you have generated]
      2. prompt_design: string [A prompt specifying how to style the HTML code]
      ### Output: A multi-line string containing complete CSS

      ## 2. generate_html
      ### Input parameters:
      1. prompt: string [A prompt specifying the complete HTML structure to generate]
      ### Output: A multi-line string containing complete HTML

      ---

      Strict requirements for every output:

      1. **JSON Standardized Output**: Every single response must be a JSON object in the following format:

      {
        "stage": "thought" | "action" | "observation" | "final",
        "action": { "action_name": {"param1": "value1", "param2": "value2"} } | null,
        "thought": "..." | null,
        "observation": "..." | null,
        "final_output": {"html": "...", "css": "..."} | null
      }

      - For stages other than the current stage, set the respective field to `null`.  
      - `stage` must indicate the current stage.  
      - `action` is only non-null in the Action stage.  
      - `thought` is only non-null in the Thought stage.  
      - `observation` is only non-null in the Observation stage.  
      - `final_output` is only non-null in the Final stage.

      2. **One Stage Per Response**: You must output exactly one stage per response and then stop. 
        Wait for the next call to continue the process.

      3. **Tool Usage**: Only use the tools listed above. Do not invent new tools.

      ---

      ### EXAMPLE:

      User Input: "I want to create a futuristic landing page for my hackathon"

      1. Thought Stage:

      {
        "stage": "thought",
        "action": null,
        "thought": "The user wants a futuristic-themed landing page for a hackathon. I should first generate the HTML structure that fits this description.",
        "observation": null,
        "final_output": null
      }

      2. Action Stage (after Thought):

      {
        "stage": "action",
        "action": {"generate_html": {"prompt": "Create a futuristic landing page for a hackathon with a hero section, event description, and a call-to-action button saying 'Register Now'"}},
        "thought": null,
        "observation": null,
        "final_output": null
      }

      3. Observation Stage (after Action):

      {
        "stage": "observation",
        "action": null,
        "thought": null,
        "observation": "<HTML output generated by generate_html tool>",
        "final_output": null
      }

      4. Thought Stage (after Observation):

      {
        "stage": "thought",
        "action": null,
        "thought": "Now that I have the HTML, I need to style it with a futuristic theme: dark background, neon-colored text and buttons, and modern fonts.",
        "observation": null,
        "final_output": null
      }

      5. Action Stage:

      {
        "stage": "action",
        "action": {"generate_css": {"html_code": "<HTML output from previous step>", "prompt_design": "Style the page with a dark background, neon text and buttons, futuristic fonts, and a sleek, modern look for a hackathon landing page"}},
        "thought": null,
        "observation": null,
        "final_output": null
      }

      6. Observation Stage:

      {
        "stage": "observation",
        "action": null,
        "thought": null,
        "observation": "<CSS output generated by generate_css tool>",
        "final_output": null
      }

      7. Final Stage:

      {
        "stage": "final",
        "action": null,
        "thought": null,
        "observation": null,
        "final_output": {
          "html": "<HTML output>",
          "css": "<CSS output>"
        }
      }
      """
    
    # Store the conversation history
    self.messages: list = []
    
    # Register tools: map tool name ("generate_html", "generate_css") to Python functions
    self.tools = {tool_name: tool_func for tool_name, tool_func in tools_list.items()}
    # {
    #   "generate_html": <function generate_html at 0x...>,
    #   "generate_css": <function generate_css at 0x...>
    # }
    
    # Add the system prompt as the first message if provided
    if self.system:
      self.messages.append({"role": "system", "content": self.system})
  
  # Wrapper to call the LLM with the conversation so far
  def call_LLM_here(self, promptCallLLM):
    response = self.client.responses.create(
      model="gpt-5",       # Use GPT-5 model
      input=promptCallLLM  # Full conversation history
    )
    outp = response.output_text  # Extract the text output
    return outp

  # Core execution loop: keeps calling the LLM until "final" stage is reached
  def execute_loop(self):
    final_output = {}
    while True:
      # Call LLM with current conversation history
      llm_text = self.call_LLM_here(self.messages)

      # Parse the LLM JSON response
      llm_output = json.loads(llm_text)
      print(llm_output)
      stageCurr = llm_output["stage"]
      # Handle "thought" and "observation" stages -> just log and continue
      if stageCurr == "thought" or stageCurr == "observation":
        print(f"------------- STAGE: {stageCurr} -------------")
        if stageCurr=="thought": print(f"Thought: {llm_output["thought"]}")
        elif stageCurr=="observation": print(f"Observation: {llm_output["observation"]}")
        print(f"----------------------------------------------")
        print()
        print()
        self.messages.append({"role": "assistant", "content": llm_text})
      
      # Handle "action" stage -> call the tool and append the tool result
      elif stageCurr == "action":
        print(f"------------- STAGE: ACTION -------------")
        print(f"Tool: {list(llm_output["action"].keys())[0]}")
        print(f"----------------------------------------------")
        print()
        print()
        tool_output = self.run_tool(llm_output["action"])
        
        observation_json = {
            "stage": "observation",
            "action": None,
            "thought": None,
            "observation": tool_output,
            "final_output": None
        }
        self.messages.append({"role": "assistant", "content": json.dumps(observation_json)})
      
      # Handle "final" stage -> break out of the loop and return the result
      elif stageCurr == "final":
        print(f"------------- STAGE: FINAL OUTPUT -------------")
        print(f"----------------------------------------------")
        print()
        print()
        final_output = llm_output["final_output"]
        break
    return final_output

  # Executes a given tool call, e.g. {"generate_html": {"prompt": "..."}}
  def run_tool(self, tool_call):
    for tool_name, params in tool_call.items():
        if tool_name not in self.tools:
            raise ValueError(f"Tool '{tool_name}' is not available.")
        
        func = self.tools[tool_name]  # Get the actual Python function
        return func(**params)         # Call it with the provided parameters
        
  # Main entrypoint: run the loop and export results to Markdown
  def __call__(self, user_input):
    if user_input:
      self.messages.append({"role": "user", "content": user_input})
    
    final_output = self.execute_loop()
    
    # Export result (HTML + CSS) to markdown file
    markdown_output = f"""
    # Code output
    ## User input: {user_input}
    ### HTML Code
    ```html\n{final_output["html"]}\n```\n
    ### CSS Code
    ```css\n{final_output["css"]}\n```\n
    """
    with open("output.md", "w") as f:
      f.write(markdown_output)

    print("Markdown with code snippet exported!")
